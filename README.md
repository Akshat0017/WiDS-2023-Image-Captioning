# WiDS-2023-Image-Captioning

The project seeks to replicate the functionality of the human brain in recognizing images and generating corresponding captions. This involves employing the advanced VGG16 Convolutional Neural Network (CNN) architecture in conjunction with Long Short-Term Memory (LSTM) and Natural Language Processing (NLP) techniques to achieve superior accuracy in results.


# Proposed Timeline:

Week 1: Focus on Numpy, Pandas, ScikitLearn, and Matplotlib.

Week 2: Dive into Pytorch and Tensorflow.

Week 3: Explore Convolutional Neural Networks (CNN).

Week 4: Delve into Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and foundational Natural Language Processing (NLP).

Week 5: Implement Image Caption Generation using the VGG-19 architecture.

# DataSet

Link to dataset for Image Caption Generation: https://www.kaggle.com/datasets/e1cd22253a9b23b073794872bf565648ddbe4f17e7fa9e74766ad3707141adeb
